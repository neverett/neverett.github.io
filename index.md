---
title: About me
---

I am a Chicago-based technical writer and data engineer. I also like to swim in Lake Michigan, make decadent lasagna, and play the viola.

## Technical writing

### Product documentation

I have written extensive technical product documentation for npm and GitHub, and generally enjoy documenting developer tools. Thanks to my data engineering experience, I'm also enthusiastic about learning and documenting cloud technologies, particularly cloud databases. I prefer writing docs in Markdown, have experienced all the highs and lows of using Jekyll for docs (particularly the Liquid template language, and YAML for reusable content), and am a quick study with any static site generator. I care deeply about accessibility; all my screenshots have alt text, my content is structured with screen readers in mind, and my tone is friendly but free of idiomatic language that makes documentation harder to localize.

I like using pull/merge requests to draft and review docs, getting and giving feedback early and often, and continuously shipping doc updates to keep pace with the speed of modern software development. I have a track record of initiating and completing ambitious, intellectually stimulating, transformative projects, and like working with similarly-inclined people.

For examples of my work, see my [portfolio page](/portfolio).

### Internal technical documentation

I like partnering with engineers and other technical experts to write docs that make their lives easier, and have written development environment setup docs, technical onboarding presentations, code style guides, troubleshooting procedures, incident response manuals, and other modern poetry. I like using GitHub wikis for internal docs, but am also proficient with Confluence, and am amenable to most any wiki software. 

## Data engineering

As a data engineer, I enjoy building ETL/ELT pipelines to transform messy data into cleaned and reshaped database tables and views that organizers, analysts, researchers, and journalists can query with confidence.

For data wrangling, I often use the PETL, polars, and Parsons Python libraries, as well as good old fashioned SQL in dbt models. I have a lot of experience using Civis Platform for pipeline orchestration, but lately I've been using Prefect Core, and sometimes even makefiles and cron jobs, depending on the needs of the project. I used Amazon Redshift extensively in my last job, MySQL in previous projects, and PostgreSQL and SQLite for my most recent data work.

I'm starting to dip my toe into data visualization with the Plotly Python library and Dash, and data publishing with Datasette, inspired by the [Public Utility Data Liberation Project (PUDL)](https://catalyst.coop/pudl/).

<hr />

I like working with people and organizations committed to police abolition, decarceration, labor power, and environmental justice. If that sounds like you, reach out to me at everettn AT protonmail DOT com or find me on [GitHub](https://github.com/neverett). For my full resume, see my [LinkedIn profile](https://linkedin.com/in/nikki-everett/).
