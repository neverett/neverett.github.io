---
title: About me
---

I am a data engineer and data analyst who lives in Chicago. I enjoy building ETL/ELT pipelines to take messy data in a variety of formats -- CSV files, API responses, database mirrors and dumps, text files, and HTML scraped from web pages -- to a cleaned and reshaped set of database tables and views that data analysts and scientists can use with confidence.

For data wrangling, I often reach for the [PETL](https://petl.readthedocs.io/en/stable/), [polars](https://pola-rs.github.io/polars/polars/index.html), and [Parsons](https://move-coop.github.io/parsons/html/stable/index.html#) Python libraries, as well as good old fashioned SQL. I am very experienced with using Civis for data orchestration, but lately I've been using Prefect Core, and sometimes even makefiles and cron jobs, depending on the needs of the project. I used AWS Redshift extensively in my last job, and have recently expanded my database skills to include PostgreSQL and SQLite.

I'm currently learning the following tools and would love to get more experience with them in my next gig:
- [pandas](https://pandas.pydata.org/)
- [dbt](https://docs.getdbt.com/)
- [Prefect](https://docs.prefect.io/2.10.15/)
- [Tableau](https://www.tableau.com/)
- [Plotly](https://plotly.com/python/) and [Dash](https://dash.plotly.com/)
- [Datasette](https://datasette.io/)

 Reach out to me at everettn AT protonmail DOT com or find me on [GitHub](https://github.com/neverett) or [Twitter](https://twitter.com/neverett).
